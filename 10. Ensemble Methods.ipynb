{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What is ensemble modelling ?\nIt means combining different machine learning models to get a better prediction"},{"metadata":{},"cell_type":"markdown","source":"### Ensemble Methods\n1. Average (or blending)\n2. Weighthed averaging\n3. Conditional averaging\n4. Bagging\n5. Boosting\n6. Stacking\n7. StackNet"},{"metadata":{},"cell_type":"markdown","source":"## Averaging ensemble methods\nConsider that you want to predict age and you have 2 models. First models had a good prediction in age < 50, but the second model had a good prediction for age >50. So we can do this **(model1 + model2) /2 ** or we can do something like **(model1 x 0.7 + model2 x 0.3)**. But this isn't good enough, there is a better way which is **Prediction of model 1 if age <50, else prediction of model 2**"},{"metadata":{},"cell_type":"markdown","source":"## Bagging\nMeans averaging slightly different versions of the same model to improve accuracy\n<t> Example of Bagging is random forest\n    \n### Parameters that control bagging ?\n- Changing the seed\n- Row (sub) sampling or Bootstrapping (create an artifical dataset)\n- Shuffling\n- Column (sub) sampling --> choose data for different features !\n- Model-specific parameters  --> make ten different model with slightly different regularization\n- Number of models (or bags)\n- (Optionally) parallelism\n"},{"metadata":{},"cell_type":"markdown","source":"## Examples of bagging\nBaggingClassifier and BaggingRegressor from sklearn\n\n```python\nmodel = RandomForestRegressor()\nbags = 10\nseed = 1\n\n# create array object to hold bagged predictions\nbagged_prediction = np.zeros(test.shape[0])\n\n# loop for as many times as we want bags\nfor n in range(0,bags):\n    model.set_params(random_state = seed + n) # update seed\n    model.fit(train,y) # fit model\n    preds = model.predict(test) # predict on test data\n    bagged_prediction += preds # add prediction to bagged predictions\n    \n# take average of predictions\nbagged_predictions /= bags```"},{"metadata":{},"cell_type":"markdown","source":"## Boosting\nA form of weighted averaging of models where each model is built sequentially via taking into account the past model performance\n\n### Main boosting types \n1. Weight based\n2. Residual based"},{"metadata":{},"cell_type":"markdown","source":"### Weight based boosting"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"rows = [[0,0.94,0.27,0.80,0.34,1,0.80,0.20,1.20], [1,0.84,0.79,0.89,0.05,1,0.75,0.25,1.25],[2,0.83,0.11,0.23,0.42,1,0.65,0.35,1.35],\n       [3,0.74,0.26,0.03,0.41,0,0.40,0.40,1.40],[4,0.08,0.29,0.76,0.37,0,0.55,0.55,1.55],[5,0.71,0.76,0.43,0.95,1,0.34,0.66,1.66],\n       [6,0.08,0.72,0.97,0.04,0,0.02,0.02,1.02]]\ndf = pd.DataFrame(rows, columns = ['Rownum','x0','x1','x2','x3','y','pred','abs.error','weight'])\ndf","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"   Rownum    x0    x1    x2    x3  y  pred  abs.error  weight\n0       0  0.94  0.27  0.80  0.34  1  0.80       0.20    1.20\n1       1  0.84  0.79  0.89  0.05  1  0.75       0.25    1.25\n2       2  0.83  0.11  0.23  0.42  1  0.65       0.35    1.35\n3       3  0.74  0.26  0.03  0.41  0  0.40       0.40    1.40\n4       4  0.08  0.29  0.76  0.37  0  0.55       0.55    1.55\n5       5  0.71  0.76  0.43  0.95  1  0.34       0.66    1.66\n6       6  0.08  0.72  0.97  0.04  0  0.02       0.02    1.02","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rownum</th>\n      <th>x0</th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>y</th>\n      <th>pred</th>\n      <th>abs.error</th>\n      <th>weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.94</td>\n      <td>0.27</td>\n      <td>0.80</td>\n      <td>0.34</td>\n      <td>1</td>\n      <td>0.80</td>\n      <td>0.20</td>\n      <td>1.20</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.84</td>\n      <td>0.79</td>\n      <td>0.89</td>\n      <td>0.05</td>\n      <td>1</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>1.25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.83</td>\n      <td>0.11</td>\n      <td>0.23</td>\n      <td>0.42</td>\n      <td>1</td>\n      <td>0.65</td>\n      <td>0.35</td>\n      <td>1.35</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.74</td>\n      <td>0.26</td>\n      <td>0.03</td>\n      <td>0.41</td>\n      <td>0</td>\n      <td>0.40</td>\n      <td>0.40</td>\n      <td>1.40</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.08</td>\n      <td>0.29</td>\n      <td>0.76</td>\n      <td>0.37</td>\n      <td>0</td>\n      <td>0.55</td>\n      <td>0.55</td>\n      <td>1.55</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>0.71</td>\n      <td>0.76</td>\n      <td>0.43</td>\n      <td>0.95</td>\n      <td>1</td>\n      <td>0.34</td>\n      <td>0.66</td>\n      <td>1.66</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>0.08</td>\n      <td>0.72</td>\n      <td>0.97</td>\n      <td>0.04</td>\n      <td>0</td>\n      <td>0.02</td>\n      <td>0.02</td>\n      <td>1.02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"There is various calculation to find the weight, but the purpose are the same. \n<t> What the weight says to the model is 'i want you to put more significance into a certain role'. You can keep repeating this process again calculate a new error based on this error, then calculate new weights --> This is how sequentially add model, maximizing the focus on where the previous models have done wrong."},{"metadata":{},"cell_type":"markdown","source":"### Weight based boosting parameters\n1. learning rate (shrinkage or eta)\n    - predictionN = pred0 + pred1 * eta + ... + predN * eta\n2. Number of estimators --> opposite relationship of learning rate\n3. Input model - can be anything that accepts weights\n4. Sub boosting type :\n    - AdaBoost - Good implementation in sklearn (python)\n    - LogitBoost - Good implementation in Weka (Java)"},{"metadata":{},"cell_type":"markdown","source":"### Residual based boosting ---> Most dominant algorithm that take person to win a competition \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = [[0,0.94,0.27,0.80,0.34,1,0.80,0.20], [1,0.84,0.79,0.89,0.05,1,0.75,0.25],[2,0.83,0.11,0.23,0.42,1,0.65,0.35],\n       [3,0.74,0.26,0.03,0.41,0,0.40,-0.40],[4,0.08,0.29,0.76,0.37,0,0.55,-0.55],[5,0.71,0.76,0.43,0.95,1,0.34,0.66],\n       [6,0.08,0.72,0.97,0.04,0,0.02,-0.02]]\ndf = pd.DataFrame(rows, columns = ['Rownum','x0','x1','x2','x3','y','pred','error'])\ndf","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"   Rownum    x0    x1    x2    x3  y  pred  error\n0       0  0.94  0.27  0.80  0.34  1  0.80   0.20\n1       1  0.84  0.79  0.89  0.05  1  0.75   0.25\n2       2  0.83  0.11  0.23  0.42  1  0.65   0.35\n3       3  0.74  0.26  0.03  0.41  0  0.40  -0.40\n4       4  0.08  0.29  0.76  0.37  0  0.55  -0.55\n5       5  0.71  0.76  0.43  0.95  1  0.34   0.66\n6       6  0.08  0.72  0.97  0.04  0  0.02  -0.02","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rownum</th>\n      <th>x0</th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>y</th>\n      <th>pred</th>\n      <th>error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.94</td>\n      <td>0.27</td>\n      <td>0.80</td>\n      <td>0.34</td>\n      <td>1</td>\n      <td>0.80</td>\n      <td>0.20</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.84</td>\n      <td>0.79</td>\n      <td>0.89</td>\n      <td>0.05</td>\n      <td>1</td>\n      <td>0.75</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.83</td>\n      <td>0.11</td>\n      <td>0.23</td>\n      <td>0.42</td>\n      <td>1</td>\n      <td>0.65</td>\n      <td>0.35</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.74</td>\n      <td>0.26</td>\n      <td>0.03</td>\n      <td>0.41</td>\n      <td>0</td>\n      <td>0.40</td>\n      <td>-0.40</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.08</td>\n      <td>0.29</td>\n      <td>0.76</td>\n      <td>0.37</td>\n      <td>0</td>\n      <td>0.55</td>\n      <td>-0.55</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>0.71</td>\n      <td>0.76</td>\n      <td>0.43</td>\n      <td>0.95</td>\n      <td>1</td>\n      <td>0.34</td>\n      <td>0.66</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>0.08</td>\n      <td>0.72</td>\n      <td>0.97</td>\n      <td>0.04</td>\n      <td>0</td>\n      <td>0.02</td>\n      <td>-0.02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Make the error become ur new prediction ! Then predict ur error"},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = [[0,0.94,0.27,0.80,0.34,0.20,0.15,0.80], [1,0.84,0.79,0.89,0.05,0.25,0.20,0.75],[2,0.83,0.11,0.23,0.42,0.35,0.40,0.65],\n       [3,0.74,0.26,0.03,0.41,-0.40,-0.30,0.40],[4,0.08,0.29,0.76,0.37,-0.55,-0.20,0.55],[5,0.71,0.76,0.43,0.95,0.66,0.24,0.34],\n       [6,0.08,0.72,0.97,0.04,-0.02, -0.01,0.02]]\ndf = pd.DataFrame(rows, columns = ['Rownum','x0','x1','x2','x3','y', 'newpred','oldpred'])\ndf","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"   Rownum    x0    x1    x2    x3     y  newpred  oldpred\n0       0  0.94  0.27  0.80  0.34  0.20     0.15     0.80\n1       1  0.84  0.79  0.89  0.05  0.25     0.20     0.75\n2       2  0.83  0.11  0.23  0.42  0.35     0.40     0.65\n3       3  0.74  0.26  0.03  0.41 -0.40    -0.30     0.40\n4       4  0.08  0.29  0.76  0.37 -0.55    -0.20     0.55\n5       5  0.71  0.76  0.43  0.95  0.66     0.24     0.34\n6       6  0.08  0.72  0.97  0.04 -0.02    -0.01     0.02","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rownum</th>\n      <th>x0</th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>y</th>\n      <th>newpred</th>\n      <th>oldpred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.94</td>\n      <td>0.27</td>\n      <td>0.80</td>\n      <td>0.34</td>\n      <td>0.20</td>\n      <td>0.15</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.84</td>\n      <td>0.79</td>\n      <td>0.89</td>\n      <td>0.05</td>\n      <td>0.25</td>\n      <td>0.20</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.83</td>\n      <td>0.11</td>\n      <td>0.23</td>\n      <td>0.42</td>\n      <td>0.35</td>\n      <td>0.40</td>\n      <td>0.65</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.74</td>\n      <td>0.26</td>\n      <td>0.03</td>\n      <td>0.41</td>\n      <td>-0.40</td>\n      <td>-0.30</td>\n      <td>0.40</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.08</td>\n      <td>0.29</td>\n      <td>0.76</td>\n      <td>0.37</td>\n      <td>-0.55</td>\n      <td>-0.20</td>\n      <td>0.55</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>0.71</td>\n      <td>0.76</td>\n      <td>0.43</td>\n      <td>0.95</td>\n      <td>0.66</td>\n      <td>0.24</td>\n      <td>0.34</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>0.08</td>\n      <td>0.72</td>\n      <td>0.97</td>\n      <td>0.04</td>\n      <td>-0.02</td>\n      <td>-0.01</td>\n      <td>0.02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"To predict Rownum=1 we would say:\n- Final prediction = 0.75 + 0.20 = 0.95"},{"metadata":{},"cell_type":"markdown","source":"### Residual based boosting parameters\n1. Learning rate (shrinkage or eta)\n    - predictionN = pred0 + pred1 * eta + ... + predN * eta, example : Prediction = 0.75 + 0.2*(0.1) = 0.77 (if lr = 0.1)\n    - Good way to handle overfit and ensure we don't rely on one model\n    \n2. Number of estimators\n    - Better more, but it takes time\n    - If it is too many, your models will have very small contribution (very small lr)\n    - Decide these parameters based on cv\n    \n3. Row(sub) sampling\n4. Column(sub) sampling\n5. Input model - better be trees.\n6. Sub boosting type :\n    - Fully gradient based\n    - Dart --> Classification problem, it imposes dropout mechanism in order to control the contribution of the trees. This dropout works like regularization. Dropout means, we dispose x% model from y model. "},{"metadata":{},"cell_type":"markdown","source":"### Residual based favourite implementations\n1. Xgboost\n2. Lightgbm\n3. H20's GBM\n4. Catboost --> strong parameters so you don't need to tuning it\n5. Sklearn's GBM --> You can put any sklearn estimator as a base"},{"metadata":{},"cell_type":"markdown","source":"## Stacking\nMeans making predictions of a number of models in a hold-out set and then using a different (Meta) model to train on these predictions."},{"metadata":{},"cell_type":"markdown","source":"### Methodology\nWolpert in 1992 introduced stacking. It involves:\n1. Splitting the train set into two disjoint sets\n2. Train several base learners on the first part\n3. Make predictions with the base learners on the second (validation) part\n4. Using all the predictions from (3) as the input to train a higher level learner\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# There are 3 dataset : A (trainset), B(validationset),  C(testset)\n\n# Train algorithm 0 on A and make predictions for B and C and save to B1,C1\n# Train algorithm 1 on A and make predictions for B and C and save to B1,C1\n# Train algorithm 2 on A and make predictions for B and C and save to B1,C1\n\nrowsB1 = [[0.24,0.72,0.70,0],[0.95,0.25,0.22,1], [0.64,0.80,0.96,0],[0.89,0.58,0.52,0],[0.11,0.20,0.93,1]]\nB1 = pd.DataFrame(rowsB1, columns = ['pred0','pred1','pred2','y'])\nB1","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"   pred0  pred1  pred2  y\n0   0.24   0.72   0.70  0\n1   0.95   0.25   0.22  1\n2   0.64   0.80   0.96  0\n3   0.89   0.58   0.52  0\n4   0.11   0.20   0.93  1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred0</th>\n      <th>pred1</th>\n      <th>pred2</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.24</td>\n      <td>0.72</td>\n      <td>0.70</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.95</td>\n      <td>0.25</td>\n      <td>0.22</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.64</td>\n      <td>0.80</td>\n      <td>0.96</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.89</td>\n      <td>0.58</td>\n      <td>0.52</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.11</td>\n      <td>0.20</td>\n      <td>0.93</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"rowsC1 = [[0.50,0.50,0.39,'?'],[0.62,0.59,0.46,'?'], [0.22,0.31,0.54,'?'],[0.90,0.47,0.09,'?'],[0.20,0.09,0.61,'?']]\nC1 = pd.DataFrame(rowsC1, columns = ['pred0','pred1','pred2','y'])\nC1","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"   pred0  pred1  pred2  y\n0   0.50   0.50   0.39  ?\n1   0.62   0.59   0.46  ?\n2   0.22   0.31   0.54  ?\n3   0.90   0.47   0.09  ?\n4   0.20   0.09   0.61  ?","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred0</th>\n      <th>pred1</th>\n      <th>pred2</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.39</td>\n      <td>?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.62</td>\n      <td>0.59</td>\n      <td>0.46</td>\n      <td>?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.22</td>\n      <td>0.31</td>\n      <td>0.54</td>\n      <td>?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.90</td>\n      <td>0.47</td>\n      <td>0.09</td>\n      <td>?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.20</td>\n      <td>0.09</td>\n      <td>0.61</td>\n      <td>?</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Then Train algorithm 3 on B1 and make predictions for C1\nrowsC1 = [[0.50,0.50,0.39,'?',0.45],[0.62,0.59,0.46,'?',0.23], [0.22,0.31,0.54,'?',0.99],[0.90,0.47,0.09,'?',0.34],[0.20,0.09,0.61,'?',0.05]]\nC1 = pd.DataFrame(rowsC1, columns = ['pred0','pred1','pred2','y','pred3'])\nC1\n\n# so pred3, basically our final prediction !","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"   pred0  pred1  pred2  y  pred3\n0   0.50   0.50   0.39  ?   0.45\n1   0.62   0.59   0.46  ?   0.23\n2   0.22   0.31   0.54  ?   0.99\n3   0.90   0.47   0.09  ?   0.34\n4   0.20   0.09   0.61  ?   0.05","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred0</th>\n      <th>pred1</th>\n      <th>pred2</th>\n      <th>y</th>\n      <th>pred3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.39</td>\n      <td>?</td>\n      <td>0.45</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.62</td>\n      <td>0.59</td>\n      <td>0.46</td>\n      <td>?</td>\n      <td>0.23</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.22</td>\n      <td>0.31</td>\n      <td>0.54</td>\n      <td>?</td>\n      <td>0.99</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.90</td>\n      <td>0.47</td>\n      <td>0.09</td>\n      <td>?</td>\n      <td>0.34</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.20</td>\n      <td>0.09</td>\n      <td>0.61</td>\n      <td>?</td>\n      <td>0.05</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"```python\n\n# Use 2 base learners\nfrom sklearn.ensemble import RandomForestRegressor #import model\nfrom sklearn.linear_model import LinearRegression #import model\nimport numpy as np #import numpy for stats\nfrom sklearn.model_selection import train_test_split # split the training data\n\n\n# split train data in 2 parts, training and validation\ntraining, valid, ytraining, yvalid = train_test_split(train,y,test_size=0.5)\n# specify models\nmodel1 = RandomForestRegressor()\nmodel2 = LinearRegression()\n# fit models\nmodel1.fit(training,ytraining)\nmodel2.fit(training,ytraining)\n# make predictions for validation\npreds1= model1.predict(valid)\npreds2= model2.predict(valid)\n# make predictions for test data\ntest_preds1 = model1.predict(test)\ntest_preds2 = model2.predict(test)\n# Form a new dataset for valid and test via stacking the predictions\nstacked_predictions = np.column_stack((preds1,preds2))\nstacked_test_predictions = np.column_stack((test_preds1, test_preds2))\n# specify meta model\nmeta_model = LinearRegression()\n# fit meta model on stacked predictions\nmeta_model.fit(stacked_predictions, yvalid)\n# make predictions on the stacked predictions of the test data\nfinal_predictions = meta_model.predict(stacked_test_predictions)```"},{"metadata":{},"cell_type":"markdown","source":"### Things to be mindful for\n1. With time sensitive data - respect time\n2. Diversity of model as important as performance. What information new model brings into the table ? Focus on this, even though the new model is weak the meta model still could get benefit.\n3. Diversity may come from:\n    - Different algorithms (nonlinear and linear)\n    - Different input features (different transformation, features, etc)\n4. Performance plateauing after N models --> There is a certain number of models when you added to get improvement\n5. Meta model is normally modest --> Generally simpler. Lower depth in case if you using randomforest"},{"metadata":{},"cell_type":"markdown","source":"## StackNet\nA scalable meta modelling methodology that utilizes stacking to combine multiple models in a neural network architecture of multiple levels"},{"metadata":{},"cell_type":"markdown","source":"### StackNet as a neural network\n- In a neural network, every node is a simple linear model ( like linear regression) with some non linear transformation\n- Instead of a linear model we could use any model\n\n\n### How to train \n- We cannot use BP (not all models are differentiable)\n- We use stacking to link each model/node with target\n- To extend to many levels, we can use a Kfold paradigm --> Better use tree model when to train the whole dataset\n- No epochs - different connections instead"},{"metadata":{},"cell_type":"markdown","source":"## TIPS AND TRICKS"},{"metadata":{},"cell_type":"markdown","source":"### First level tips\n1. Diversity based on algorithms:\n    - 2-3 Gradient boosted trees (lightgb, xgboost,H20,catboost). Try with bigger depth, low depth, etc\n    - 2-3 Neural nets (keras, pytorch) 3 hidden layers, 1 hidden layers --> make slightly different to get new information\n    - 1-2 ExtraTrees/RandomForest (sklearn)\n    - 1-2 linear models as in logistic/ridge regression, linear svm (sklearn)\n    - 1-2 knn models (sklearn)\n    - 1 Factorization machine (libfm)\n    - 1 svm with nonlinear kernel if size/memory allows (sklearn)\n    \n2. Diversity based on input data:\n    - Categorical features: One hot, label encoding, target encoding\n    - Numerical features: outliers, binning, derivatives, percentiles, scalling\n    - Interactions: Col1 /+-* Col2, groupby (given a groupby categorical features, calculate the average features), unsupervised (Kmeans, svm, "},{"metadata":{},"cell_type":"markdown","source":"### Subsequent level tips\n1. Simple (or shallower) algorithms:\n    - Gradient boosted trees with small depth (like 2 or 3)\n    - Linear models with high regularization\n    - Extra Trees --> Don't make them too big\n    - Shallow networks (as in 1 hidden layer)\n    - knn with BrayCurtis Distance\n    - Brute forcing a search for best linear weights based on cv\n    \n2. Feature Engineering:\n    - pairwise differences between meta features\n    - row-wise statistics like averages or stds\n\n3. For every 7.5 models in previous level we add 1 in meta\n4. Be mindful of target leakage --> Control K value in cv \n "},{"metadata":{},"cell_type":"markdown","source":"### Software for Stacking\n- StackNet (https://github.com/kaz-Anova/StackNet)\n- Stacked ensembles from H20\n- Xcessiv (https://github.com/reiinakano/xcessiv)\n\n\n### Tips about StackNet (Software)\n- The parameters sectio. Choose the most important parameters\n- Always save your code and re-use it \n- Seek collaborations\n- Read forums/kernels"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}