{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"titanic_train = pd.read_csv('/kaggle/input/titanic/train.csv')\ntitanic_test = pd.read_csv('/kaggle/input/titanic/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"EDA allows to:\n- Better understand the data, because complete data understanding is used to generate new features and to build accurate model.\n- Build an intuition about the data.\n- Generate hypothesizes.\n- Find insights."},{"metadata":{},"cell_type":"markdown","source":"## Visualizations\n\nWhen you see visualize your data, we immediately see the pattern :\n What are those pattern ? and why do we see them ? \n How do we use those pattern to build a better model ?\n \nWhen you have hypothesis about the data, what do we do ? :\n We have to tested it with visualization !\n \n \nWE WILL TALK ABOUT THE MAIN VISUALIZATION TOOLS !"},{"metadata":{},"cell_type":"markdown","source":"Motivating Example :\n- Alexandaer D'yakonov participate a competition that you don't have to modelling, you just have to understanding better the data.\n- The competition objective is whether a person will use the promo that a company offers him ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"row = [[14,13,4,1], [3,43,35,0], [0,6,0,1], [32,15,13,1]]\ndata = pd.DataFrame(row, columns = ['person_id','#promos_sent','#promos_used','used_this_promo?'])\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Among the features there are 2 special things :\n1. the number of promos sended before\n2. the number of promos had used before\n\nDo the following :\n1. For each pearson sort by '#promos_sent'\n2. Look at difference between consecutive rows in '#promos_used' column ('diff' feature)"},{"metadata":{"trusted":true},"cell_type":"code","source":"row = [[13,0,0,1,1], [13,1,1,0,0],[13,2,1,1,0],[13,4,2,1,1],[13,5,3,0,0],[13,6,3,np.nan,0]]\ndata_sorted = pd.DataFrame(row, columns = ['person_id','#promos_sent','#promos_used','diff','used_this_promo?'])\ndata_sorted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"See the diff feature, in most cases is equal to the target values.\n\nSee the fifth row, if a person had already used the promo, so the current promo customer will not use the promo again !\nBut if a person not yet used a promo, he tend to be use the promo that has been given to him.\n\nIt is not clear with the last row (NaN), but without model Alexandaer get 80% accuracy.\nThis is the power of Visualization because we are now better to understand the data.\n\n\n- This is called leaks data"},{"metadata":{},"cell_type":"markdown","source":"### SUMMARY\n\n*With EDA we can: *\n- get comfortable with the data\n- find magic features\n\nDo EDA first ! Do not immediately dig into modelling."},{"metadata":{},"cell_type":"markdown","source":"# Step when you want to do EDA"},{"metadata":{},"cell_type":"markdown","source":"## Getting domain Knowledge"},{"metadata":{"trusted":true},"cell_type":"code","source":"row = [['78db044136','s', 0.28,'s_2',3,0],['68a0110c33','s', 1,'s_2',1,13],['2r39fw11w3','p', 1.2,'p_1',3,419]]\ndf = pd.DataFrame(row , columns = ['AdGroupId','AdNetworkType2','Maxcpc','Slot','Clicks','Impressions'])\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From google we know that Clicks is always less than the impressions, because impressions means that how many ads that show in a website while Click how many click that user do to the adds!"},{"metadata":{},"cell_type":"markdown","source":"## Checking if the data is intuitive"},{"metadata":{"trusted":true},"cell_type":"code","source":"age = pd.Series([23,20,19,336,35,31])\nage","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Is 336 a typo ?\n2. Or we misinterpret the feature and age 336 is normal ? Confirm the dataset information !\n3. Sometimes the errors may not be a random, but maybe there is a logic why there is an error in that particular place. This mistakes can be use to get a better score."},{"metadata":{"trusted":true},"cell_type":"code","source":"row = [['78db044136','s', 0.28,'s_2',3,0,True],['68a0110c33','s', 1,'s_2',1,13,False],['2r39fw11w3','p', 1.2,'p_1',3,419,False]]\ndf = pd.DataFrame(row , columns = ['AdGroupId','AdNetworkType2','Maxcpc','Slot','Clicks','Impressions','is_incorrect'])\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We know that in the first row, there is an error, so we can take a beneficial from this with make a new feature is_incorrect "},{"metadata":{},"cell_type":"markdown","source":"## Understand How the data was generated\n\n- What is the algorithm to sampling the data from database ?\n- Maybe with random sampling or maybe with oversample on a particular class so the classes will balances.\n- If you know how the data was generated, you can set up a proper validation scheme.\n- Maybe the train set and the test set was generated with different algorithm. So, if the test set is different with train set, we cannot use part of train set as a validation set.\n  Because this part will not be representating of test set. Thus, we cannot evaluate our model using it."},{"metadata":{},"cell_type":"markdown","source":"1. If most visualization of train set are much different from test set, it means train set and test set are not similar (Different algorithm when data is generated) ! \n2. Adjust the train set to match the test set, so the validation score became more reliable. How ?"},{"metadata":{},"cell_type":"markdown","source":"Example side note :\n###days in train > #days in test\n###rows in train < #rows in test\n\nThere is different train set and test set generated in here. Be Careful !"},{"metadata":{},"cell_type":"markdown","source":"### Conclusion\n- Get domain knowledge: it helps to deeper understand the problem\n- Check if the data is intuitive And agrees with domain knowledge\n- Understand how the data was generated: As it is crucial to set up a proper validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}